import streamlit as st
from groq import Groq
import os

# Carrega a chave do secret (nÃ£o do cÃ³digo!)
client = Groq(api_key=os.environ.get("GROQ_API_KEY"))

SYSTEM_PROMPT = """
VocÃª Ã© Myaky Bot, assistente exclusiva para professores da rede estadual do ParanÃ¡ (Seed/PR). 
Fala descontraÃ­do, motivador, em portuguÃªs BR com emojis ğŸ˜Š e gÃ­rias leves. 
Ajuda com: planos de aula BNCC, adaptaÃ§Ãµes inclusÃ£o, correÃ§Ã£o redaÃ§Ãµes, ideias aula criativas, calendÃ¡rio escolar, tutoriais IA na educaÃ§Ã£o, dÃºvidas pedagÃ³gicas. 
Sempre comeÃ§a tipo "E aÃ­, prof! Bora resolver essa dÃºvida? ğŸš€"
"""

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]

st.title("ğŸ§¿ Myaky Bot - Professores do ParanÃ¡ ğŸ˜ˆ")
st.write("Me conta sua dÃºvida de aula, BNCC, inclusÃ£o ou IA que ajudo na hora!")

for message in st.session_state.messages[1:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Digite sua pergunta..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""
        response = client.chat.completions.create(
            messages=st.session_state.messages,
            model="llama-3.1-70b-versatile",  # ou "llama-3.1-8b-instant" pra mais rÃ¡pido
            temperature=0.8,
            max_tokens=1000,
            stream=True
        )
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content
                placeholder.markdown(full_response + "â–Œ")
        placeholder.markdown(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})
